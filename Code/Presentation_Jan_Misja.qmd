---
title: "Bayesiaanse Beleidsanalyse"

date: today
institute: "Tilburg University and University of Twente"
author: "Jan Boone & Misja Mikkers"
date-format: long
lang: nl
format:
  revealjs:
    logo: logo.png
    
    slide-number: c/t #< collapsed/total
    self-contained: true
    editor: visual
    footer: "Jan Boone & Misja Mikkers — Bayesiaanse Beleidsanalyse"
    
bibliography: references.bib
editor: visual
css: custom.css  
---

## Inleiding

```{r}
library(tidyverse)  # For data manipulation
library(ggforce)  # For ellipse
library(dagitty) # voor DAGS
library(ggdag) # voor mooiere DAGS
library(brms) # bayesian analyse
library(broom) # voor tidy regressie resultaten
library(broom.mixed) # broom voor brms
library(tidybayes) # voor extracting samples

options(scipen = 9999) # Disable scientific notation



```

## Quiz: Hoe interpreteer jij waarschijnlijkheid?

::: {style="font-size: 0.8em;"}
We starten met een korte quiz (gebaseerd op @johnson2022bayes) met vier vragen om te ontdekken hoe jij naar waarschijnlijkheid kijkt.

**Instructies voor deelnemers**

-   Lees iedere vraag zorgvuldig.
-   Bespreek je antwoorden kort met je buurvrouw of man.
-   Noteer je antwoorden (A, B of C) op papier.
-   We bespreken de antwoorden en de achterliggende gedachten plenair na de quiz.
:::

## Vraag 1

::: {style="font-size: 0.8em;"}
Bij het opgooien van een eerlijke munt zeggen we dat de kans op ‘kop’ 0,5 is. Hoe interpreteer jij deze kans?

A)  Als ik de munt heel vaak opgooi, komt ongeveer 50% kop.\
B)  Kop en munt zijn nu even plausibel.\
C)  Beide interpretaties (A en B) zijn logisch.
:::

## Vraag 2

::: {style="font-size: 0.8em;"}
Elf dagen voor de verkiezingen gaf FiveThirtyEight Trump een kans van 51% om te winnen. Hoe interpreteer jij deze kans?

A)  Als we de verkiezingen 100 keer zouden houden, wint Trump 51 keer.\
B)  Trump heeft iets meer kans om te winnen dan om te verliezen.\
C)  Dit slaat nergens op: Trump wint of verliest, de kans is 0 of 1.
:::

## Vraag 3

::: {style="font-size: 0.8em;"}
We laten 2 statements zien:

1.  Tessa zegt dat ze elk liedje van Taylor Swift binnen 30 seconden kan herkennen. Ze wordt getest: 7 liedjes, 7 keer goed.

2.  Paul de Octopus voorspelde in 2010 de uitslag van alle 7 WK-wedstrijden van Duitsland correct.

Wat denk jij?

A)  Ik vertrouw meer op Tessa’s claim dan op die van Paul.\
B)  Het bewijs voor Tessa en Paul is even sterk.
:::

## Vraag 4

::: {style="font-size: 0.8em;"}
Een arts zegt dat je positief hebt getest op een zeldzame ziekte. Wat is de belangrijkste vraag om te stellen?

A)  Wat is de kans dat ik écht ziek ben?\
B)  Wat is de kans dat ik een positieve test krijg als ik níet ziek ben?
:::

::: notes
Hier draait het om een klassiek probleem in medische statistiek:

-   A vraagt naar de *"post test kans"* — de kans dat je echt ziek bent gegeven de positieve test (positieve predictieve waarde).
-   B vraagt naar het *vals-positiefpercentage* — kans op een fout-positieve test bij gezonde mensen.

Beide perspectieven zijn belangrijk, maar A is de vraag die je écht wil stellen. Hier biedt de formule van Bayes het antwoord: we updaten onze overtuiging op basis van de test (data) en de zeldzaamheid van de ziekte (prior.

We kunnen dit eventueel visueel laten zien? [zoiets?](https://www.youtube.com/watch?v=HZGCoVF3YvM)
:::

## Tellen van je score

::: {style="font-size: 0.8em;"}
Tel je punten op:

| Vraag | A (punten) | B (punten) | C (punten) |
|-------|------------|------------|------------|
| 1     | 1          | 3          | 2          |
| 2     | 1          | 3          | 1          |
| 3     | 3          | 1          |            |
| 4     | 3          | 1          |            |

**Interpretatie van je score**

-   4–5 punten: Je denkt nu vooral Frequentistisch.
-   6–8 punten: Je ziet sterke kanten in beide benaderingen.
-   9–12 punten: Je neigt sterk naar het Bayesiaanse denken.
:::

## Frequentistisch versus Bayesiaans: de belangrijkste verschillen

::: {style="font-size: 0.8em;"}
| Aspect          | Frequentistisch              | Bayesiaans                    |
|------------------|--------------------------|----------------------------|
| Kans (P)        | Lange termijn frequentie     | Geloofsgraad / plausibiliteit |
| Focus           | Variabiliteit van data       | Onzekerheid over uitkomsten   |
| Informatiebron  | Data                         | Data + voorkennis (‘priors’)  |
| Wat je berekent | $P(\text{data | hypothese})$ | $P(\text{hypothese | data})$  |
:::

# Bayesian Learning en updating

## Bayesian Learning

```{r}

ggplot() +
  annotate("text", x = 20, y = 10, label = "Prior belief", size = 5) +
  geom_ellipse(aes(x0 = 20, y0 = 10, a = 13, b = 5, angle = 0), fill = "blue", alpha = 0.2) +
  annotate("text", x = 50, y = 10, label = "Data", size = 5) +
  geom_ellipse(aes(x0 = 50, y0 = 10, a = 13, b = 5, angle = 0), fill = "blue", alpha = 0.2) +
  annotate("text", x = 35, y = 40, label = "Updated belief", size = 5) +
  geom_ellipse(aes(x0 = 35, y0 = 40, a = 13, b = 5, angle = 0), fill = "blue", alpha = 0.2) +
  annotate("text", x = 65, y = 40, label = "Data", size = 5) +
  geom_ellipse(aes(x0 = 65, y0 = 40, a = 13, b = 5, angle = 0), fill = "blue", alpha = 0.2) +
  annotate("text", x = 50, y = 70, label = "Updated belief", size = 5) +
  geom_ellipse(aes(x0 = 50, y0 = 70, a = 13, b = 5, angle = 0), fill = "blue", alpha = 0.2) +
  annotate("text", x = 80, y = 70, label = "Data", size = 5) +
  geom_ellipse(aes(x0 = 80, y0 = 70, a = 13, b = 5, angle = 0), fill = "blue", alpha = 0.2) +
  geom_segment(aes(x = 20, y = 15, xend = 33, yend = 34), lineend = "round", arrow = arrow(type = "closed", length = unit(0.1, "inches"))) +
  geom_segment(aes(x = 50, y = 15, xend = 37, yend = 34), lineend = "round", arrow = arrow(type = "closed", length = unit(0.1, "inches"))) +
  geom_segment(aes(x = 35, y = 45, xend = 48, yend = 64), lineend = "round", arrow = arrow(type = "closed", length = unit(0.1, "inches"))) +
  geom_segment(aes(x = 65, y = 45, xend = 52, yend = 64), lineend = "round", arrow = arrow(type = "closed", length = unit(0.1, "inches"))) +
  geom_segment(aes(x = 50, y = 75, xend = 63, yend = 94), lineend = "round", linetype = "dashed",  arrow = arrow(type = "closed", length = unit(0.1, "inches"))) +
   geom_segment(aes(x = 80, y = 75, xend = 67, yend = 94), lineend = "round", linetype = "dashed",  arrow = arrow(type = "closed", length = unit(0.1, "inches"))) +
  xlim(0, 100) +
  ylim(0, 100) +
  theme_void() +
  labs(caption = "adapted from Johnson et al. (2022)")

```

## Bayesian Learning

![](images/Bayes.png){fig-align="center"}

# Voorbeeld Bayesiaanse updating

## Welk percentage van de aarde is bedekt met water?

```{r}
# Original dataset and processing
d <- tibble(toss = c("w", "l", "w", "w", "w", "l", "w", "l", "w"))

d <- d %>%
  mutate(n_trials  = 1:9,
         n_success = cumsum(toss == "w"))

sequence_length <- 50
d <- d %>%
  expand(nesting(n_trials, toss, n_success),
         p_water = seq(from = 0, to = 1, length.out = sequence_length)) %>%
  group_by(p_water) %>%
  # Use lag() without specifying k
  mutate(
    lagged_n_trials  = lag(n_trials, 1),  # Updated usage
    lagged_n_success = lag(n_success, 1)  # Updated usage
  ) %>%
  ungroup() %>%
  mutate(
    prior      = ifelse(n_trials == 1, 0.5,
                        dbinom(x    = lagged_n_success,
                               size = lagged_n_trials,
                               prob = p_water)),
    likelihood = dbinom(x    = n_success,
                        size = n_trials,
                        prob = p_water),
    strip      = str_c("n = ", n_trials)
  ) %>%
  # Normalize the prior and the likelihood to make them proper probabilities
  group_by(n_trials) %>%
  mutate(
    prior      = prior / sum(prior, na.rm = TRUE),
    likelihood = likelihood / sum(likelihood, na.rm = TRUE)
  )

LABEL <- d %>%
  group_by(n_trials) %>%
  summarise(toss = first(toss), strip = first(strip),
            y_position = max(prior, likelihood, na.rm = TRUE) * 0.85) %>%
  mutate(Label = case_when(
    toss == "w" ~ "Water",
    TRUE ~ "Land"  # Default value if toss is not "w"
  ))
```

```{r}
prior_data <- d %>%
  filter(n_trials == 1) %>%
  select(p_water, prior) 

 prior <- ggplot(data = prior_data, aes(x = p_water)) +
    geom_line(aes(y = prior), linetype = 2, size = 0.8) + # Adjust line size
    scale_x_continuous("proportion water", breaks = c(0, .5, 1)) +
    scale_y_continuous("plausibility", breaks = NULL) +
    theme(panel.grid = element_blank()) +
    theme_bw(base_size = 10) + 
     theme(legend.position = "none")

ggsave(prior, filename = "../Figures/prior.png", width = 4, height = 4)

```

![](images/globe.jpg){fig-align="center"}

Het voorbeeld is ontleend aan @mcelreath2018statistical

## Tossing the globe {.scrollable}

```{r}


# Loop through each trial and create separate plots
for (i in 1:9) {
  d_subset <- d %>% filter(n_trials == i)
  LABEL_subset <- LABEL %>% filter(n_trials == i)

  p <- ggplot(data = d_subset, aes(x = p_water)) +
    geom_line(aes(y = prior), linetype = 2, size = 0.8) + # Adjust line size
    geom_line(aes(y = likelihood), size = 0.8) + # Adjust line size
    scale_x_continuous("proportion water", breaks = c(0, .5, 1)) +
    scale_y_continuous("plausibility", breaks = NULL) +
    theme(panel.grid = element_blank()) +
    facet_wrap(~strip, scales = "free_y", nrow = 1) + # Adjust the number of rows
    theme_bw(base_size = 10) + 
    geom_text(data = LABEL_subset,
              aes(x = 0.15, y = y_position,
                  label = paste("Toss:", Label), color = Label),
              vjust = -1, size = 5) +
    scale_color_manual(values = c("Land" = "darkgreen", "Water" =  "steelblue")) +
    theme(legend.position = "none")

  # Save each plot as an image with appropriate dimensions
  ggsave(filename = paste0("../Figures/bayesian_update_plot_n_", i, ".png"), plot = p, width = 6, height = 4)
}



```

::: {.absolute-container style="position: relative; width: 100%; height: 100%;"}
<!-- Prior Plot -->

![](../Figures/prior.png){.absolute .fragment top="10%" left="5%" width="25%" height="25%"}

<!-- Update Plot 1 -->

![](../Figures/bayesian_update_plot_n_1.png){.absolute .fragment top="10%" left="35%" width="25%" height="25%"}

<!-- Update Plot 2 -->

![](../Figures/bayesian_update_plot_n_2.png){.absolute .fragment top="10%" left="65%" width="25%" height="25%"}

<!-- Update Plot 3 -->

![](../Figures/bayesian_update_plot_n_3.png){.absolute .fragment top="40%" left="5%" width="25%" height="25%"}

<!-- Update Plot 4 -->

![](../Figures/bayesian_update_plot_n_4.png){.absolute .fragment top="40%" left="35%" width="25%" height="25%"}

<!-- Update Plot 5 -->

![](../Figures/bayesian_update_plot_n_5.png){.absolute .fragment top="40%" left="65%" width="25%" height="25%"}

<!-- Update Plot 6 -->

![](../Figures/bayesian_update_plot_n_6.png){.absolute .fragment top="70%" left="5%" width="25%" height="25%"}

<!-- Update Plot 7 -->

![](../Figures/bayesian_update_plot_n_7.png){.absolute .fragment top="70%" left="35%" width="25%" height="25%"}

<!-- Update Plot 8 -->

![](../Figures/bayesian_update_plot_n_8.png){.absolute .fragment top="70%" left="65%" width="25%" height="25%"}
:::

## Eerste Bayesiaanse analyse: het DGP

```{r}
lengtedag1 <- dagitty('dag {
Lengte [outcome, pos = "1,0"]
Geslacht [exposure, pos = "0,1"]
Onbekend [unobserved, pos = "1,1"] 

Geslacht -> Lengte
Onbekend -> Lengte

}')

lengtedag <- tidy_dagitty(lengtedag1)

lengtedag[["data"]] <- lengtedag[["data"]] %>%
  mutate(Kleur = as.factor(c(1, 2, 3)))

cols <- c("1" = "#f00000", "2" = "#a8862d", "3" = "#00bfff")

ggdag(lengtedag) + 
   geom_dag_point(aes(color = Kleur)) +
  geom_dag_text(col = "black") +
  theme_void() +
  theme(
  panel.background = element_rect(fill = "white",
                                colour = "white",
                                linewidth = 0.5, linetype = "solid"),
  panel.grid.major = element_line(size = 0.5, linetype = 'solid',
                                colour = "white"), 
  panel.grid.minor = element_line(size = 0.25, linetype = 'solid',
                                colour = "white")
  ) +
 xlim(-0.5,2.5) +
 ylim(-0.5,1.5) + 
  theme(legend.position = "none") +
  scale_color_manual(values = cols)


```

## Eerste Bayesiaanse analyse

```{r eerste analyse}

set.seed(123)

df_l <- tibble(
  persoon_id = 1:100000,
  Mannen = rnorm(n = 100000, mean = 181, sd = 12),
  Vrouwen = rnorm(n = 100000, mean = 167, sd = 10)
) %>%
  pivot_longer(cols = c(Mannen, Vrouwen), names_to = "Geslacht", values_to = "Lengte") %>%
  mutate(Geslacht = factor(Geslacht, levels = c("Mannen", "Vrouwen")))

summ_df_l <- df_l %>%
  group_by(Geslacht) %>%
  summarise(Gemiddelde = round(mean(Lengte),1))

ggplot() +
  geom_histogram(data = df_l, aes(x = Lengte, fill = Geslacht), alpha = 0.5, color = "black") +
  geom_vline(data = summ_df_l, aes(xintercept = Gemiddelde, color = Geslacht), linetype = "dashed", show.legend = FALSE) +
  geom_text(data = summ_df_l, aes(x = Gemiddelde + 5, y = 15000, label = Gemiddelde, color = Geslacht), show.legend = FALSE, size = 3) +
  theme_bw() +
  scale_fill_manual(values = c("Mannen" = "steelblue4", 
                               "Vrouwen" = "firebrick")) +
  scale_color_manual(values = c("Mannen" = "steelblue4", 
                               "Vrouwen" = "firebrick")) +
  labs(x = "Lengte in centimeters", fill = " ", y = "Count")  +
  facet_wrap(~ Geslacht, ncol = 1)
  





```

## Schatting model met veel data en strakke prior

```{r}

fullrun <- 0


Formula <- Lengte ~ 0 + Intercept + Geslacht
    
prior1 <- c(set_prior("normal(175, 20)", class = "b", coef = "Intercept"),
            set_prior("normal(0,1)", class = "b", coef = "GeslachtVrouwen"))    # idioot strakke prior om te laten zien dat de prior wordt verzwolgen door de data. Door prior vermoedelijk wel iets te lage schatting verschil

if(fullrun){
  

model_l <- brm(
            formula = Formula,
            prior = prior1,
            data   = df_l,
            warmup = 500, 
            iter   = 1500, 
            chains = 4, 
            init  = "random",
            cores  = 2,
            seed = 123,
            silent = TRUE)

saveRDS(model_l, "../Data/model_l.rds")
} else {
 model_l <- readRDS("../Data/model_l.rds")}


```

```{r}

## ik heb geprobeerd de prior en de data te laten zien, maar dat lukt niet echt goed omdat de sitributie van de data breed is en daarmee niet zichtbaar is op de y-as.

# posteror samples
samples_l <- tidy_draws(model_l, "^b") %>%
  dplyr::select(starts_with("b_")) %>%
  dplyr::select(Vrouwen = b_GeslachtVrouwen)  


ggplot() +
  geom_density(data = samples_l, aes(x = Vrouwen), 
               fill = "firebrick", alpha = 0.5) +
  geom_vline(xintercept = 167 - 181, color = "firebrick", linetype = "dashed") +
  theme_bw() +
  expand_limits(x = c(0, -20)) +
  labs(x = "Verschil tussen mannen en vrouwen", title = "model met veel data en strakke prior", y = "Density") +
  annotate(geom = "text", x = -5, y = 7, 
           label = "n = 200.000\n priors\n lengte : normal(175, 20)\n verschil m/v normal(0,1)") +
  xlim(c(-20, 20))


 


```

## Nu zelfde schatting met heel beperkte data!

```{r eerste analyse beperkte sample}

set.seed(123)

df_la <- tibble(Mannen = rnorm(n = 10, mean = 181, sd = 12),
              Vrouwen = rnorm(n = 10, mean = 167, sd = 10)) %>%
  pivot_longer(cols = 1:2, names_to = "Geslacht", values_to = "Lengte")

df_la$Geslacht <- factor(df_la$Geslacht, levels = c("Mannen", "Vrouwen"))

summ_df_la <- df_la %>%
  group_by(Geslacht) %>%
  summarise(Gemiddelde = round(mean(Lengte),1))

ggplot() +
  geom_histogram(data = df_la, aes(x = Lengte, fill = Geslacht), alpha = 0.5, color = "black", bins = 4) +
  geom_vline(data = summ_df_la, aes(xintercept = Gemiddelde, color = Geslacht), linetype = "dashed", show.legend = FALSE) +
   geom_text(data = summ_df_la, aes(x = Gemiddelde + 5, y = 9, label = Gemiddelde, color = Geslacht), show.legend = FALSE, size = 3) +
  theme_bw() +
  scale_fill_manual(values = c("Mannen" = "steelblue4", 
                               "Vrouwen" = "firebrick")) +
  scale_color_manual(values = c("Mannen" = "steelblue4", 
                               "Vrouwen" = "firebrick")) +
  labs(x = "Lengte in centimeters", fill = " ", y = "Count") +
  facet_wrap(~ Geslacht, ncol = 1)





```

## Resultaat

```{r}


df_la_wide <- df_la %>%
  group_by(Geslacht) %>%
  mutate(id = row_number()) %>%
  pivot_wider(names_from = Geslacht, values_from = Lengte) %>%
  mutate(Verschil = Vrouwen - Mannen) 
  

fullrun <- 0


Formula <- Lengte ~ 0 + Intercept + Geslacht
    
prior1 <- c(set_prior("normal(175, 20)", class = "b", coef = "Intercept"),
            set_prior("normal(0,1)", class = "b", coef = "GeslachtVrouwen"))    

if(fullrun){
  

model_la <- brm(
            formula = Formula,
            prior = prior1,
            data   = df_la,
            warmup = 500, 
            iter   = 1500, 
            chains = 4, 
            init  = "random",
            cores  = 4,
            seed = 123,
            silent = TRUE)

saveRDS(model_la, "../Data/model_la.rds")
} else {
 model_la <- readRDS("../Data/model_la.rds")}


```

```{r}

samples_la <- tidy_draws(model_la, "^b") %>%
  dplyr::select(starts_with("b_")) %>%
  dplyr::select(Vrouwen = b_GeslachtVrouwen) 
  
ggplot() +
  geom_density(data = samples_la, aes(x = Vrouwen), 
               fill = "firebrick", alpha = 0.5) +
  geom_vline(xintercept = 167 - 181, color = "firebrick", linetype = "dashed") +
  geom_vline(xintercept = mean(df_la_wide$Verschil), color = "steelblue", linetype = "dashed") +
   annotate("text", x = 167 - 181, y = 0.25, label = "Echte verschil", angle = 90, vjust = -0.5, color = "firebrick") +
  annotate("text", x = mean(df_la_wide$Verschil), y = 0.25, label = "Gemiddelde verschil in data", angle = 90, vjust = 1, color = "steelblue") +
  annotate("text", x = 167 - 181, y = 0.25, label = "Echte verschil", angle = 90, vjust = -0.5, color = "firebrick") +
    theme_bw() +
    labs(x = "Verschil tussen mannen en vrouwen", title = "Strakke prior en weinig data", y = "Density") +
  annotate(geom = "text", x = -5, y = 0.3, 
           label = "n = 20\n priors\n lengte : normal(175, 20)\n verschil m/v normal(0,1)") +
  xlim(c(-20, 20))


 



```

## Schatting model met kleine sample size en betere prior

```{r}



fullrun <- 0


Formula <- Lengte ~ 0 + Intercept + Geslacht
    
prior1 <- c(set_prior("normal(175, 20)", class = "b", coef = "Intercept"),
            set_prior("normal(-10,5)", class = "b", coef = "GeslachtVrouwen"))    

if(fullrun){
  

model_lb <- brm(
            formula = Formula,
            prior = prior1,
            data   = df_la,
            warmup = 500, 
            iter   = 1500, 
            chains = 4, 
            init  = "random",
            cores  = 2,
            seed = 123,
            silent = TRUE)

saveRDS(model_lb, "../Data/model_lb.rds")
} else {
 model_lb <- readRDS("../Data/model_lb.rds")}


samples_lb <- tidy_draws(model_lb, "^b") %>%
  dplyr::select(starts_with("b_")) %>%
  dplyr::select(Vrouwen = b_GeslachtVrouwen) 
  
ggplot() +
  geom_density(data = samples_lb, aes(x = Vrouwen), 
               fill = "firebrick", alpha = 0.5) +
  geom_vline(xintercept = 167 - 181, color = "firebrick", linetype = "dashed") +
  geom_vline(xintercept = mean(df_la_wide$Verschil), color = "steelblue", linetype = "dashed") +
  theme_bw() +
     annotate("text", x = 167 - 181, y = 0.22, label = "Echte verschil", angle = 90, vjust = -0.5, color = "firebrick") +
  annotate("text", x = mean(df_la_wide$Verschil), y = 0.22, label = "Gemiddelde verschil in data", angle = 90, vjust = 1, color = "steelblue") +
  labs(x = "Verschil tussen mannen en vrouwen", title = "Goede prior en weinig data", y = "Density") +
  annotate(geom = "text", x = 0, y = 0.25, 
           label = "n = 20\n priors\n lengte : normal(175, 20)\n verschil m/v normal(-10,5)") +
  xlim(c(-20, 20)) +
  ylim(0,0.3)




```

## Met nulhypothese

```{r}

fullrun <- 0


Formula <- Lengte ~ 0 + Intercept + Geslacht
    
prior1 <- c(set_prior("normal(175, 20)", class = "b", coef = "Intercept"),
            set_prior("normal(0,5)", class = "b", coef = "GeslachtVrouwen"))    

if(fullrun){
  

model_null <- brm(
            formula = Formula,
            prior = prior1,
            data   = df_la,
            warmup = 500, 
            iter   = 1500, 
            chains = 4, 
            init  = "random",
            cores  = 2,
            seed = 123,
            silent = TRUE)

saveRDS(model_null, "../Data/model_null.rds")
} else {
 model_null <- readRDS("../Data/model_null.rds")}



samples_null <- tidy_draws(model_null, "^b") %>%
  dplyr::select(starts_with("b_")) %>%
  dplyr::select(Vrouwen = b_GeslachtVrouwen) 
  

```

```{r}


# Dataframe voor de prior
prior_df <- tibble(
  x = seq(-60, 60, length.out = 500),
  y = dnorm(x, mean = 0, sd = 5)
)

ggplot() +
  # Prior (als dichtheidsvlak)
  geom_area(data = prior_df, aes(x = x, y = y, fill = "Prior"),color = "grey50", alpha = 0.3) +
  
  # Posterior (uit samples)
  geom_density(data = samples_null, aes(x = Vrouwen, fill = "Posterior"), alpha = 0.5) +
  
  # Verschil in data
  geom_density(data = df_la_wide, aes(x = Vrouwen - Mannen, fill = "Data"), alpha = 0.5) +
  geom_vline(xintercept = 167 - 181, color = "firebrick", linetype = "dashed") +
  geom_vline(xintercept = mean(df_la_wide$Verschil), color = "steelblue", linetype = "dashed") +
   annotate("text", x = 167 - 181, y = 0.2, label = "Echte verschil", angle = 90, vjust = -0.5, color = "firebrick") +
  annotate("text", x = mean(df_la_wide$Verschil), y = 0.2, label = "Gemiddelde verschil in data", angle = 90, vjust = 1, color = "steelblue") +
  
  scale_fill_manual(values = c(
    "Prior" = "gold", 
    "Posterior" = "firebrick", 
    "Data" = "steelblue"
  )) +
  labs(x = "Verschil tussen mannen en vrouwen", title = "Nul hypothese", y = "Density", fill = " ") +
  annotate(geom = "text", x = 10, y = 0.2, 
           label = "n = 20\n priors\n lengte : normal(175, 20)\n verschil m/v normal(0,5)") +
  theme_bw() +
xlim(-40, 40) +
  ylim(0,0.3)




```

# Een beleidsvoorbeeld

## In de praktijk: onzekerheid over beleidsanalyse

::: {style="font-size: 0.7em;"}
-   de onzekerheid over de schatting van coefficienten vertaalt zich in onzekerheid van beleidsrelevante keuzes
-   een voorbeeld:
    -   de overheid wil een publiek goed van 18k (per capita) financieren met inkomensbelasting
    -   er is belasting systeem met 3 schuiven en een oplopende marginale belasting tarief
    -   wij schatten de (Pareto) verdeling van inkomens
    -   de onzekerheid van de schatting van deze parameters bepaalt of het lukt om het publieke goed te financieren
    -   dit is een niet lineare transformatie van de onzekerheid, frequentisme is hier niet goed in
:::

## Simulatie

![](images/income_distribution.png){fig-align="center"}

::: {style="font-size: 0.4em;"}
-   de geschatte parameters $\alpha, m$ van de Pareto verdeling hebben een verdeling gegeven de data

-   posterior verdeling: $p(\alpha,m|data)$

-   het algoritme sampled van deze verdeling: er zijn 4000 $\alpha$ and $m$ (4 keer 1000 samples)
:::

::: notes
-   we hebben sample gegenereerd van een Pareto inkomens verdeling

-   met sample hebben we de parameters van deze verdeling geschat
:::

## Onzekerheid

-   voor een geven $\alpha, m$, is er een belasting opbrengst (met de niet lineare belasting functie)
-   voor 4000 $\alpha, m$ is er een verdeling van deze belasting opbrengt

![verdeling belasting opbrengst](images/average_tax_income_distributions.png){fig-align="center"}

## Significantie

-   stel de verwachte belasting opbrengst is 17k (per capita)
-   is dit significant verschil met benchmark 18k?
-   is helemaal niet relevant voor beleidsanalyse
-   Bayesiaan: verwachte belasting opbrengst is 18,336k
-   kans dat de threshold niet gehaald wordt is 58%

## Wat is een goede keuze voor het top marginal tarief

![kans dat de benchmark gehaald wordt](images/probabilities.png)

## Andere voorbeelden

::: {style="font-size: 0.8em;"}
-   arbeidsaanbod elasticteit: totale belasting opbrengsten als functie van marginal tarief inkomsten belasting
-   eigen risico elasticeit: total zorg uitgaven
-   vraagelasticiteit NS: prijzen treinkaartjes, hoeveel autos op de weg
-   onzekerheid over de schattingen die niet triviaal vertaald in onzekerheid over beleidsuitkomsten
-   geintegreerde schattingsmethode en scenario analyse
-   monitoren/leren tijdens een beleidsexperiment \[zoals bijvoorbeeld in Amsterdam-Noord\]
:::

## Literatuur
